# -*- coding: utf-8 -*-
"""Image_classification(cifar).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z5Phr6fpcWfN1J5ejx_6lqfU4kX3C22k
"""

import tarfile
tar = tarfile.open("/content/drive/MyDrive/cifar-100-python.tar.gz","r:gz")

tar.extractall("/content/drive/MyDrive/cifar")
tar.close()

def unpickle(file):
    import pickle
    with open(file, 'rb') as fo:
        dict = pickle.load(fo, encoding='bytes')
    return dict
train=unpickle("/content/drive/MyDrive/cifar/cifar-100-python/train")

test=unpickle("/content/drive/MyDrive/cifar/cifar-100-python/test")



from keras.datasets import cifar100

(xtrain,ytrain),(xtest,ytest)=cifar100.load_data(label_mode="fine")

from keras import models
from keras import layers

model = models.Sequential()
model.add(layers.Conv2D(16, (3, 3), activation='relu',input_shape=(32,32, 3)))
model.add(layers.Conv2D(32, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(256, (3, 3), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(512, activation='relu'))
model.add(layers.BatchNormalization())
model.add(layers.Dense(512, activation='relu'))
#model.add(layers.Dropout(0.3))
model.add(layers.BatchNormalization())
model.add(layers.Dense(100, activation='softmax'))

model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics='accuracy')

history=model.fit(xtrain,ytrain,epochs=20,validation_split=.2)

